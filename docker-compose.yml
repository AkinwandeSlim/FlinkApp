version: "3.9"

services:
  kafka:
    image: wurstmeister/kafka:2.13-2.7.0
    depends_on:
      - zookeeper
    ports:
      - "9091:9091"
    expose:
      - "9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:9091
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:9091
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  zookeeper:
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"

  producer:
    build:
      context: .
      dockerfile: producer/Dockerfile
    depends_on:
      - kafka
    environment:
      SCRIPT: producer/producer.py
      DATA: data/sea_a2.csv
      KAFKA_HOST: kafka:9092
      KAFKA_TOPIC: train_in_1
      KAFKA_INTERVAL: 0.9
      
      
  mysql1:
    image: mysql:8.0.22     # 5.7 版本本地连接不上
    command: [
        '--default-authentication-plugin=mysql_native_password',
        '--character-set-server=utf8mb4',
        '--collation-server=utf8mb4_unicode_ci',
        '--log-bin=mysql-bin',
    ]
    ports:
      - 3306:3306
    environment:
      MYSQL_ROOT_PASSWORD: root
    volumes:
      - ./examples/mysql:/docker-entrypoint-initdb.d
    container_name: mysql1
  mysql2:
    image: mysql:8.0.22          # 5.7 版本本地连接不上
    command: [
        '--default-authentication-plugin=mysql_native_password',
        '--character-set-server=utf8mb4',
        '--collation-server=utf8mb4_unicode_ci'
    ]
    ports:
      - 3307:3306                # 第二个数据库的端口是 3307
    environment:
      MYSQL_ROOT_PASSWORD: root
    volumes:
      - ./examples/mysql:/docker-entrypoint-initdb.d
    container_name: mysql2
  adminer:
    image: adminer
    ports:
      - 8080:8080
    container_name: adminer
  redis:
    image: redis:6.0.9
    ports:
      - 6379:6379
    command:
      # 设置 redis 密码为 redis_password
      redis-server --requirepass redis_password --appendonly yes
    container_name: redis 



       
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.8.0
    environment:
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - discovery.type=single-node
    ports:
      - "9200:9200"
      - "9300:9300"
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
  kibana:
    image: docker.elastic.co/kibana/kibana:7.8.0
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
  load-kibana-dashboard:
    build: ./kibana
    command: ['/bin/bash', '-c', 'cat /tmp/load/load_ndjson.sh | tr -d "\r" | bash']
    depends_on:
      - kibana


  consumer_flink:
    build:
      context: .
      dockerfile: consumer_flink/Dockerfile
    ports:
      - "8081:8081"
    environment:
      SCRIPT: consumer_flink/consumer_flink.py
      KAFKA_HOST: kafka:9092
      ZOOKEEPER_HOST: zookeeper:2181
      KAFKA_TOPIC: train_in_1
      KAFKA_CONSUMER_GROUP: Flink-Group
      
     
      


#   jobmanager:
#     build: .
#     image: pyflink/pyflink:1.11.2-scala_2.11
#     container_name: jobmanager
#     volumes:
#       - ./consumer_flink:/opt/consumer_flink
#     hostname: "jobmanager"
#     expose:
#       - "6123"
#     ports:
#       - "8081:8081"
#     command: jobmanager
#     environment:
#       - JOB_MANAGER_RPC_ADDRESS=jobmanager
#   taskmanager:
#     image: pyflink/pyflink:1.11.2-scala_2.11
#     container_name: taskmanager
#     volumes:
#     - ./consumer_flink:/opt/consumer_flink/
#     expose:
#       - "6121"
#       - "6122"
#     depends_on:
#       - jobmanager
#     command: taskmanager
#     links:
#       - jobmanager:jobmanager
#     environment:
#       - JOB_MANAGER_RPC_ADDRESS=jobmanager      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
# version: "3.5"
# services:

#   kafka:
#     image: wurstmeister/kafka:2.13-2.6.0
#     volumes:
#       - /etc/localtime:/etc/localtime      ## kafka 镜像和宿主机器之间时间保持一致
#     ports:
#       - "9092:9092"                        ## 对外暴露的 kafka 端口号
#     depends_on:
#       - zookeeper
#     environment:
#       KAFKA_ADVERTISED_HOST_NAME: localhost
#       KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
#       KAFKA_ADVERTISED_PORT: 9092
#       KAFKA_BROKER_ID: 1
#       KAFKA_LOG_RETENTION_HOURS: 120
#       KAFKA_MESSAGE_MAX_BYTES: 10000000
#       KAFKA_REPLICA_FETCH_MAX_BYTES: 10000000
#       KAFKA_GROUP_MAX_SESSION_TIMEOUT_MS: 60000
#       KAFKA_NUM_PARTITIONS: 3
#       KAFKA_DELETE_RETENTION_MS: 1000
#       KAFKA_CREATE_TOPICS: "stream-in:1:1,stream-out:1:1"      ## 自动创建 topics
#     container_name: kafka
    